{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best model for coconut copra type using supervised learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib untuk manipulasi data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib untuk analisa statistik\n",
    "import scipy.stats as sc\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# lib untuk visualisasi data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# lib untuk praproses dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# lib untuk klasifikasi data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "\n",
    "# library untuk evaluasi model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# lib disble warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- config models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config models\n",
    "experiments = 7   # fill number 1 until 7\n",
    "splitting = 90  # fill number 90 or 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"dataset/ekstrasi-fitur-kopra-nonTelungkup_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show metadata\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset\n",
    "np.round(dataset, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variabel warna, bentuk, texture\n",
    "color = [\"Mean_R\", \"Mean_G\", \"Mean_B\", \"Mean_H\", \"Mean_V\", \"Mean_S\", \"Mean_Gray\", \"Standar_Deviasi\"]\n",
    "shape = [\"Luas\", \"Perimeter\"]\n",
    "texture = [\"Contrast\", \"Dissimilarity\", \"Homogeneity\", \"Energy\", \"Correlation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment and feature\n",
    "# experiment 1\n",
    "if experiments == 1:\n",
    "  exp = \"Experiments 1\"\n",
    "  x = dataset[color].values\n",
    "\n",
    "# experiment 2\n",
    "if experiments == 2:\n",
    "  exp = \"Experiments 2\"\n",
    "  x = dataset[shape].values\n",
    "\n",
    "# experiment 3\n",
    "if experiments == 3:\n",
    "  exp = \"Experiments 3\"\n",
    "  x = dataset[texture].values\n",
    "\n",
    "# experiment 4\n",
    "if experiments == 4:\n",
    "  exp = \"Experiments 4\"\n",
    "  x = dataset[color + shape].values\n",
    "\n",
    "# experiment 5\n",
    "if experiments == 5:\n",
    "  exp = \"Experiments 5\"\n",
    "  x = dataset[color + texture].values\n",
    "\n",
    "# experiment 6\n",
    "if experiments == 6:\n",
    "  exp = \"Experiments 6\"\n",
    "  x = dataset[shape + texture].values\n",
    "\n",
    "# experiment 7\n",
    "if experiments == 7:\n",
    "  exp = \"Experiments 7\"\n",
    "  x = dataset[color + shape + texture].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show feature\n",
    "print(np.round(x,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set label, dependent variable\n",
    "y = dataset[[\"Class\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show feature\n",
    "print(np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(scaled, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split validation\n",
    "if splitting == 80:\n",
    "  trainX, testX, trainY, testY = train_test_split(scaled, y, train_size=0.8, test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "# split validation\n",
    "if splitting == 90:\n",
    "  trainX, testX, trainY, testY = train_test_split(scaled, y, train_size=0.9, test_size=0.1, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape labels\n",
    "trainY = trainY.reshape(-1)\n",
    "testY = testY.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dimension of data train\n",
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dimension of data test\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised learning algorithm\n",
    "result_KNN = KNeighborsClassifier(n_neighbors=3).fit(trainX, trainY).predict(testX)\n",
    "result_SVC = SVC(kernel='linear').fit(trainX, trainY).predict(testX)\n",
    "result_C45 = DecisionTreeClassifier(criterion=\"gini\", random_state=0).fit(trainX, trainY).predict(testX)\n",
    "result_GNB = GaussianNB().fit(trainX, trainY).predict(testX)\n",
    "result_LR = LogisticRegression(max_iter=1000).fit(trainX, trainY).predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all result with labels\n",
    "data = {\n",
    "  \"KNN\" : result_KNN,\n",
    "  \"SVC\" : result_SVC,\n",
    "  \"C45\" : result_C45,\n",
    "  \"GNB\" : result_GNB,\n",
    "  \"LR\" : result_LR,\n",
    "  \"Labels\": testY,\n",
    "}\n",
    "\n",
    "# convert result to dataframe\n",
    "result = pd.DataFrame(data)\n",
    "\n",
    "# show dataframe\n",
    "np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy, Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Supervised Learning: \"+str(exp)+\" and train test \"+str(splitting)+\"%\")\n",
    "print(\"\")\n",
    "for i in range(len(result.columns)-1):\n",
    "    print(result.columns[i])\n",
    "    print(np.round(accuracy_score(result[\"Labels\"], result.iloc[:,i:i+1]), 3))\n",
    "    print(np.round(precision_score(result[\"Labels\"], result.iloc[:,i:i+1], average=\"macro\"), 3))\n",
    "    print(np.round(recall_score(result[\"Labels\"], result.iloc[:,i:i+1], average=\"macro\"), 3))\n",
    "    print(np.round(f1_score(result[\"Labels\"], result.iloc[:,i:i+1], average=\"macro\"), 3))\n",
    "    print(\"------------------------- \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_plotly(df):\n",
    "  # plotting heatmap corr\n",
    "  fig = px.imshow(\n",
    "    img=df,\n",
    "    x = ['1', '2', '3'],\n",
    "    y = ['1', '2', '3'],\n",
    "    color_continuous_scale = 'RdYlGn_r',\n",
    "    aspect=True,\n",
    "    text_auto=True,\n",
    "  )\n",
    "  \n",
    "  fig.update_traces(\n",
    "    xgap=3, ygap=3,\n",
    "    textfont={\"size\":16}, \n",
    "  )\n",
    "\n",
    "  # customize layout\n",
    "  fig.update_layout(\n",
    "    width=450, height=360,\n",
    "    #title=algorithms,\n",
    "  )\n",
    "\n",
    "  # # show heatmap corr\n",
    "  # fig.show()\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_matplotlib(data):\n",
    "  # Data sampel\n",
    "  x = [\"1\", \"2\", \"3\"]\n",
    "  y = [\"1\", \"2\", \"3\"]\n",
    "  data = np.array(data)\n",
    "\n",
    "  # create figure\n",
    "  fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "  # create heatmap\n",
    "  plt.imshow(data, cmap='RdYlGn_r')\n",
    "\n",
    "  # Show all ticks and label them with the respective list entries\n",
    "  ax.set_xticks(np.arange(len(x)), labels=x)\n",
    "  ax.set_yticks(np.arange(len(y)), labels=y)\n",
    "\n",
    "  # Loop over data dimensions and create text annotations.\n",
    "  for i in range(len(x)):\n",
    "    for j in range(len(y)):\n",
    "      text = ax.text(j, i, data[i, j], ha=\"center\", va=\"center\", fontsize=12)\n",
    "\n",
    "  # show heatmap\n",
    "  return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_plotly(pd.DataFrame(confusion_matrix(testY, result_KNN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_plotly(pd.DataFrame(confusion_matrix(testY, result_SVC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_plotly(pd.DataFrame(confusion_matrix(testY, result_C45)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_plotly(pd.DataFrame(confusion_matrix(testY, result_GNB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_plotly(pd.DataFrame(confusion_matrix(testY, result_LR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
